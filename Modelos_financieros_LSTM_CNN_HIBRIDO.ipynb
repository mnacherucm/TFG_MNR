{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414f4282",
   "metadata": {},
   "source": [
    "# Redes neuronales aplicadas a series financieras\n",
    "Este notebook compara tres modelos distintos de redes neuronales aplicadas a la predicción de series temporales financieras. Incluye técnicas de normalización, ventanas deslizantes y distintas arquitecturas.\n",
    "\n",
    "**Modelos incluidos:**\n",
    "- LSTM clásico\n",
    "- CNN 1D\n",
    "- Híbrido CNN + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63058ec7",
   "metadata": {},
   "source": [
    "## 1. Modelo LSTM para predicción bursátil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f5d3a2",
   "metadata": {},
   "source": [
    "# Stock price prediction using LSTM neural network and Tensorflow\n",
    "What do we need here:\n",
    "1. Load data\n",
    "2. Scale data for machine learning model\n",
    "3. Setup neural network\n",
    "4. Compile model\n",
    "5. Teach neural netowk and fit this\n",
    "6. Use the model for prediction\n",
    "7. Draw the results chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad87d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "!pip install yahoo_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2541422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as tm\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data preparation\n",
    "from yahoo_fin import stock_info as yf #acceder a información financiera y datos de acciones de Yahoo Finance de manera programática\n",
    "from sklearn.preprocessing import MinMaxScaler #escalar o normalizar datos dentro de un rango específico\n",
    "from collections import deque #estructura de datos similar a una lista, pero optimizada para realizar operaciones de inserción y eliminación en ambos extremos con mayor eficiencia\n",
    "\n",
    "# AI\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "# Graphics library\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTINGS\n",
    "\n",
    "# Window size or the sequence length, 7 (1 week)\n",
    "N_STEPS = 7\n",
    "\n",
    "# Lookup steps, 1 is the next day, 3 = after tomorrow\n",
    "LOOKUP_STEPS = [1, 2, 3]\n",
    "\n",
    "# Stock ticker, GOOGL\n",
    "STOCK = 'GOOGL'\n",
    "\n",
    "# Current date\n",
    "date_now = tm.strftime('%Y-%m-%d')\n",
    "date_3_years_back = (dt.date.today() - dt.timedelta(days=1104)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "# from yahoo_fin\n",
    "# for 1104 bars with interval = 1d (one day)\n",
    "init_df = yf.get_data(\n",
    "    STOCK,\n",
    "    start_date=date_3_years_back,\n",
    "    end_date=date_now,\n",
    "    interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns which our neural network will not use\n",
    "init_df = init_df.drop(['open', 'high', 'low', 'adjclose', 'ticker', 'volume'], axis=1)\n",
    "# create the column 'date' based on index column\n",
    "init_df['date'] = init_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ddf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's preliminary see our data on the graphic\n",
    "plt.style.use(style='ggplot')\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(init_df['close'][-200:])\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('price')\n",
    "plt.legend([f'Actual price for {STOCK}'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c6062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data for ML engine\n",
    "scaler = MinMaxScaler()\n",
    "init_df['scaled_close'] = scaler.fit_transform(np.expand_dims(init_df['close'].values, axis=1))\n",
    "#Crea una nueva columna en el DataFrame init_df llamada scaled_close, que contiene los valores escalados entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82151824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARAMOS LOS DATOS\n",
    "def PrepareData(days):\n",
    "  #days: Número de días hacia adelante que se quiere predecir\n",
    "  df = init_df.copy()\n",
    "  #copia del DataFrame original para trabajar sin modificar los datos originales\n",
    "  df['future'] = df['scaled_close'].shift(-days)\n",
    "  #Crea una nueva columna, future, que contiene los valores futuros de scaled_close,\n",
    "  # desplazados hacia arriba por el número de días definido en days. Esto\n",
    "  # representa los valores objetivo\n",
    "  last_sequence = np.array(df[['scaled_close']].tail(days))\n",
    "  # Guarda los últimos days valores de la columna scaled_close como un array\n",
    "  # NumPy\n",
    "  df.dropna(inplace=True)\n",
    "  # Elimina las filas con valores NaN, que ocurren en las últimas filas debido\n",
    "  # al desplazamiento con shift\n",
    "  sequence_data = []\n",
    "  sequences = deque(maxlen=N_STEPS)\n",
    "\n",
    "  for entry, target in zip(df[['scaled_close'] + ['date']].values, df['future'].values):\n",
    "      sequences.append(entry)\n",
    "      if len(sequences) == N_STEPS:\n",
    "          sequence_data.append([np.array(sequences), target])\n",
    "  #sequence_data: Una lista con pares [secuencia, valor_futuro] para entrenar el modelo\n",
    "\n",
    "  last_sequence = list([s[:len(['scaled_close'])] for s in sequences]) + list(last_sequence)\n",
    "  last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "  #last_sequence: La última ventana deslizante para predecir valores futuros después del entrenamiento\n",
    "\n",
    "  # construct the X's and Y's\n",
    "  X, Y = [], []\n",
    "  for seq, target in sequence_data:\n",
    "      X.append(seq)\n",
    "      Y.append(target)\n",
    "\n",
    "  # convert to numpy arrays\n",
    "  X = np.array(X)\n",
    "  Y = np.array(Y)\n",
    "\n",
    "  return df, last_sequence, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9380ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PrepareData(3) # 3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76968078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrainedModel(x_train, y_train):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(60, return_sequences=True, input_shape=(N_STEPS, len(['scaled_close']))))\n",
    "  model.add(Dropout(0.3))\n",
    "  model.add(LSTM(120, return_sequences=False))\n",
    "  model.add(Dropout(0.3))\n",
    "  model.add(Dense(20))\n",
    "  model.add(Dense(1))\n",
    "\n",
    "  BATCH_SIZE = 8\n",
    "  EPOCHS = 80\n",
    "\n",
    "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "  model.fit(x_train, y_train,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            epochs=EPOCHS,\n",
    "            verbose=1)\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f423a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET PREDICTIONS\n",
    "predictions = []\n",
    "\n",
    "for step in LOOKUP_STEPS:\n",
    "  df, last_sequence, x_train, y_train = PrepareData(step)\n",
    "  x_train = x_train[:, :, :len(['scaled_close'])].astype(np.float32)\n",
    "\n",
    "  model = GetTrainedModel(x_train, y_train)\n",
    "\n",
    "  last_sequence = last_sequence[-N_STEPS:]\n",
    "  last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "  prediction = model.predict(last_sequence)\n",
    "  predicted_price = scaler.inverse_transform(prediction)[0][0]\n",
    "\n",
    "  predictions.append(round(float(predicted_price), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d527fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bool(predictions) == True and len(predictions) > 0:\n",
    "  #Comprueba si la lista predictions no está vacía\n",
    "  predictions_list = [str(d)+'$' for d in predictions]\n",
    "  #Toma cada valor de predictions (almacena los precios predichos) y lo convierte en una cadena\n",
    "  predictions_str = ', '.join(predictions_list)\n",
    "  message = f'{STOCK} prediction for upcoming 3 days ({predictions_str})'\n",
    "\n",
    "  print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258048ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute model for the whole history range\n",
    "copy_df = init_df.copy()\n",
    "y_predicted = model.predict(x_train)\n",
    "y_predicted_transformed = np.squeeze(scaler.inverse_transform(y_predicted))\n",
    "#Convierte las predicciones escaladas de vuelta a su rango original\n",
    "#Elimina cualquier dimensión extra en el array. Si y_predicted tiene la forma (n_samples, 1), ahora será un array 1D de forma (n_samples,)\n",
    "first_seq = scaler.inverse_transform(np.expand_dims(y_train[:6], axis=1))\n",
    "#Selecciona los primeros 6 valores del conjunto de entrenamiento (y_train) y los desescala para devolverlos a su rango original\n",
    "last_seq = scaler.inverse_transform(np.expand_dims(y_train[-3:], axis=1))\n",
    "#últimos 3 valores de y_train y los desescala\n",
    "y_predicted_transformed = np.append(first_seq, y_predicted_transformed)\n",
    "y_predicted_transformed = np.append(y_predicted_transformed, last_seq)\n",
    "copy_df[f'predicted_close'] = y_predicted_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4056804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predicted results to the table\n",
    "date_now = dt.date.today()\n",
    "date_tomorrow = dt.date.today() + dt.timedelta(days=1)\n",
    "date_after_tomorrow = dt.date.today() + dt.timedelta(days=2)\n",
    "\n",
    "copy_df.loc[date_now] = [predictions[0], f'{date_now}', 0, 0]\n",
    "copy_df.loc[date_tomorrow] = [predictions[1], f'{date_tomorrow}', 0, 0]\n",
    "copy_df.loc[date_after_tomorrow] = [predictions[2], f'{date_after_tomorrow}', 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result chart\n",
    "plt.style.use(style='ggplot')\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(copy_df['close'][-150:].head(147))\n",
    "plt.plot(copy_df['predicted_close'][-150:].head(147), linewidth=1, linestyle='dashed')\n",
    "plt.plot(copy_df['close'][-150:].tail(4))\n",
    "plt.xlabel('days')\n",
    "plt.ylabel('price')\n",
    "plt.legend([f'Actual price for {STOCK}',\n",
    "            f'Predicted price for {STOCK}',\n",
    "            f'Predicted price for future 3 days'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d101b",
   "metadata": {},
   "source": [
    "# RESUMEN\n",
    "### Propósito del modelo\n",
    "El objetivo es predecir los precios futuros de acciones (específicamente para el ticker GOOGL) utilizando datos históricos mediante una red neuronal LSTM implementada con TensorFlow/Keras.\n",
    "\n",
    "### Pasos clave según el notebook\n",
    "1. Carga de datos:\n",
    "- Se utiliza la biblioteca yahoo_fin para extraer datos históricos de precios de acciones.\n",
    "- Los datos abarcan los últimos 1104 días (alrededor de 3 años) con intervalos diarios (1d).\n",
    "2. Preparación de los datos:\n",
    "- Escalado: Los datos de precios se normalizan usando MinMaxScaler para ajustarlos a un rango entre 0 y 1.\n",
    "- Ventanas deslizantes: Se preparan ventanas de datos de tamaño N_STEPS = 7 (una semana) para alimentar la red LSTM.\n",
    "3. Arquitectura de la red neuronal:\n",
    "- Utiliza Keras con un modelo Sequential:\n",
    "- Capa LSTM inicial con 60 neuronas y return_sequences=True.\n",
    "- Dropout del 30% para evitar sobreajuste.\n",
    "- Segunda capa LSTM con 120 neuronas y return_sequences=False.\n",
    "- Capas densas intermedias con 20 neuronas.\n",
    "- Una capa densa final con 1 neurona para predecir un valor único (el precio futuro).\n",
    "- Función de pérdida: mean_squared_error.\n",
    "- Optimizador: adam.\n",
    "4. Entrenamiento del modelo:\n",
    "- Se entrena el modelo con BATCH_SIZE = 8 y EPOCHS = 80.\n",
    "5. Predicciones:\n",
    "- El modelo realiza predicciones para los próximos días (LOOKUP_STEPS = [1, 2, 3]).\n",
    "- Las predicciones escaladas se desescalan utilizando MinMaxScaler para obtener los valores originales.\n",
    "6. Visualización de resultados:\n",
    "- Se genera un gráfico que compara los precios reales con las predicciones del modelo (incluidas las proyecciones futuras).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc80212",
   "metadata": {},
   "source": [
    "## 2. Modelo CNN 1D aplicado al índice China A50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17017618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(\"000001.SS\", start=\"2023-01-22\",  end = \"2025-01-22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b7d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficar precios de cierre\n",
    "plt.figure(figsize=(12, 6))  # Ajustar el tamaño de la figura\n",
    "plt.plot(data['Close'], label='Closing Price', color='blue')\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.title('Shanghai Composite Index (Closing Prices)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Closing Price (CNY)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Eliminar filas con valores faltantes\n",
    "data = data.dropna()\n",
    "\n",
    "# Crear etiquetas basadas en el cambio del precio de cierre después de 10 días\n",
    "def create_labels(data, days=10):\n",
    "    labels = []\n",
    "    close_values = data['Close'].values  # Convertimos la columna a un array de NumPy\n",
    "    for i in range(len(close_values) - days):\n",
    "        if close_values[i + days] > close_values[i]:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    # Agregar ceros para los últimos días sin etiquetas\n",
    "    labels += [0] * days\n",
    "    return labels\n",
    "\n",
    "data['Label'] = create_labels(data)\n",
    "\n",
    "# Remover los últimos 10 días porque no tienen etiquetas válidas\n",
    "data = data[:-10]\n",
    "\n",
    "# Normalizar las características (min-max normalization)\n",
    "scaler = MinMaxScaler()\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data[features] = scaler.fit_transform(data[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d268091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preparar las entradas (X) y las etiquetas (y)\n",
    "# Convierte el subconjunto de pandas (DataFrame) en un array de NumPy\n",
    "X = data[features].values\n",
    "y = data['Label'].values\n",
    "\n",
    "# Transformar las entradas en forma de 3D para la CNN\n",
    "# Formato: (n_samples, n_timesteps, n_features)\n",
    "n_timesteps = 10  # Número de pasos de tiempo\n",
    "X_cnn = []\n",
    "y_cnn = []\n",
    "for i in range(len(X) - n_timesteps):\n",
    "  #Extrae una submatriz de tamaño (n_timesteps, n_features)\n",
    "    X_cnn.append(X[i:i + n_timesteps])\n",
    "    y_cnn.append(y[i + n_timesteps])\n",
    "\n",
    "X_cnn = np.array(X_cnn)\n",
    "y_cnn = np.array(y_cnn)\n",
    "\n",
    "# Dividir los datos en entrenamiento (80%) y prueba (20%)\n",
    "#ensuring that the model is trained on earlier data and tested on later data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cnn, y_cnn, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Imprimir la forma de los datos\n",
    "print(\"Forma de X_train:\", X_train.shape)  # (n_samples_train, n_timesteps, n_features)\n",
    "print(\"Forma de y_train:\", y_train.shape)  # (n_samples_train,)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba331750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Parámetros del modelo\n",
    "n_classes = 2         # Clasificación binaria\n",
    "dropout_rate = 0.8    # Dropout para evitar sobreajuste\n",
    "learning_rate = 0.0001  # Tasa de aprendizaje\n",
    "batch_size = 1000     # Tamaño del batch\n",
    "\n",
    "# Crear el modelo CNN\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, strides=1, activation='relu', input_shape=(10, 5)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, strides=1))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, strides=1))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, strides=1))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=1 - dropout_rate))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "              loss=SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "# Supongamos que tienes datos de entrenamiento `X_train` y `y_train` preparados\n",
    "# X_train: Datos de entrada con forma (n_samples, n_timesteps, n_features)\n",
    "# y_train: Etiquetas con forma (n_samples, )\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=40,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cdce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo con datos de prueba\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Pérdida en los datos de prueba: {loss:.4f}\")\n",
    "print(f\"Exactitud en los datos de prueba: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9a58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener predicciones\n",
    "y_pred_prob = model.predict(X_test)  # Probabilidades predichas\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convertir probabilidades a clases\n",
    "\n",
    "print(\"Predicciones:\", y_pred)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Calcular métricas\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133bf002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficar pérdida\n",
    "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Graficar exactitud\n",
    "plt.plot(history.history['accuracy'], label='Exactitud de entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Exactitud de validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b0446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44da1de0",
   "metadata": {},
   "source": [
    "## 3. Modelo híbrido CNN + LSTM aplicado a datos financieros reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cbf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Conv1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Fetch Stock Data from Yahoo Finance\n",
    "stock_symbol = \"AAPL\"  # You can change this to any stock symbol\n",
    "df = yf.download(stock_symbol, start=\"2020-01-01\", end=\"2024-01-01\")\n",
    "df = df[['Close']]\n",
    "\n",
    "# Data Preprocessing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "print(df_scaled.shape)\n",
    "\n",
    "# Convert to time series data for training\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LENGTH = 50  # Number of days to look back\n",
    "X, y = create_sequences(df_scaled, SEQ_LENGTH)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split into training and testing\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "# Reshape for CNN input\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "\n",
    "\n",
    "# Define Models\n",
    "def build_rnn():\n",
    "    model = Sequential([\n",
    "        SimpleRNN(50, activation=\"relu\", return_sequences=True, input_shape=(SEQ_LENGTH, 1)),\n",
    "        SimpleRNN(50, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_lstm():\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation=\"relu\", return_sequences=True, input_shape=(SEQ_LENGTH, 1)),\n",
    "        LSTM(50, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_cnn():\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation=\"relu\", input_shape=(SEQ_LENGTH, 1)),\n",
    "        Flatten(),\n",
    "        Dense(50, activation=\"relu\"),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# Train models\n",
    "rnn_model = build_rnn()\n",
    "lstm_model = build_lstm()\n",
    "cnn_model = build_cnn()\n",
    "\n",
    "history_rnn = rnn_model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "history_lstm = lstm_model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "history_cnn = cnn_model.fit(X_train_cnn, y_train, epochs=20, batch_size=16, validation_data=(X_test_cnn, y_test), verbose=1)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rnn = rnn_model.predict(X_test)\n",
    "y_pred_lstm = lstm_model.predict(X_test)\n",
    "y_pred_cnn = cnn_model.predict(X_test_cnn)\n",
    "\n",
    "# Inverse transform predictions\n",
    "y_pred_rnn = scaler.inverse_transform(y_pred_rnn)\n",
    "y_pred_lstm = scaler.inverse_transform(y_pred_lstm)\n",
    "y_pred_cnn = scaler.inverse_transform(y_pred_cnn)\n",
    "y_test_actual = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Compute metrics\n",
    "mae_rnn = mean_absolute_error(y_test_actual, y_pred_rnn)\n",
    "mse_rnn = mean_squared_error(y_test_actual, y_pred_rnn)\n",
    "\n",
    "mae_lstm = mean_absolute_error(y_test_actual, y_pred_lstm)\n",
    "mse_lstm = mean_squared_error(y_test_actual, y_pred_lstm)\n",
    "\n",
    "mae_cnn = mean_absolute_error(y_test_actual, y_pred_cnn)\n",
    "mse_cnn = mean_squared_error(y_test_actual, y_pred_cnn)\n",
    "\n",
    "# Plot predictions vs actual prices\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_actual, label=\"Actual Price\", color='black')\n",
    "plt.plot(y_pred_rnn, label=\"RNN Prediction\", linestyle=\"dashed\")\n",
    "plt.plot(y_pred_lstm, label=\"LSTM Prediction\", linestyle=\"dotted\")\n",
    "plt.plot(y_pred_cnn, label=\"CNN Prediction\", linestyle=\"dashdot\")\n",
    "plt.legend()\n",
    "plt.title(\"Stock Price Prediction Comparison\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.show()\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": [\"RNN\", \"LSTM\", \"CNN\"],\n",
    "    \"MAE\": [mae_rnn, mae_lstm, mae_cnn],\n",
    "    \"MSE\": [mse_rnn, mse_lstm, mse_cnn]\n",
    "})\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285499bd",
   "metadata": {},
   "source": [
    "## 4. Comparación visual y conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo opcional para comparar visualmente predicciones\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(y_test, label='Real')\n",
    "# plt.plot(y_pred_lstm, label='LSTM')\n",
    "# plt.plot(y_pred_cnn, label='CNN')\n",
    "# plt.plot(y_pred_hybrid, label='CNN + LSTM')\n",
    "# plt.legend()\n",
    "# plt.title('Comparación de modelos sobre datos financieros')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
